{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# S3 credentials\n",
    "ACCESS_KEY = 'AKIAWPPO6VXLYSOLWFE7'\n",
    "SECRET_KEY = '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'\n",
    "BUCKET_NAME = 'dmml-storage-bits'\n",
    "REGION = 'eu-north-1'\n",
    "\n",
    "# Create S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY,\n",
    "                      aws_secret_access_key=SECRET_KEY,\n",
    "                      region_name=REGION)\n",
    "\n",
    "# PostgreSQL connection details\n",
    "host = 'database-dmml.cluster-czyuk8c4op6k.eu-north-1.rds.amazonaws.com'\n",
    "port = 5432\n",
    "database = 'postgres'\n",
    "username = 'postgres'\n",
    "password = 'dmml-project-postgres'\n",
    "schema = 'public'\n",
    "table_name = 'customer_churn_analysis'\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database,\n",
    "    user=username,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM customer_churn_analysis\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['churn'] = label_encoder.fit_transform(df['churn'])\n",
    "\n",
    "X = df.drop(['customerid','churn'], axis=1)  # Features\n",
    "y = df['churn']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize/scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "logistic_regression = LogisticRegression()\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "\n",
    "# Train Random Forest Model\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Logistic Regression Evaluation\n",
    "accuracy_lr, precision_lr, recall_lr, f1_lr = evaluate_model(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_lr:.2f}\")\n",
    "print(f\"Precision: {precision_lr:.2f}\")\n",
    "print(f\"Recall: {recall_lr:.2f}\")\n",
    "print(f\"F1 Score: {f1_lr:.2f}\")\n",
    "\n",
    "# Random Forest Evaluation\n",
    "accuracy_rf, precision_rf, recall_rf, f1_rf = evaluate_model(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
    "print(f\"Precision: {precision_rf:.2f}\")\n",
    "print(f\"Recall: {recall_rf:.2f}\")\n",
    "print(f\"F1 Score: {f1_rf:.2f}\")\n",
    "\n",
    "logistic_regression_model_filename = \"logreg_model.pkl\"\n",
    "random_forest_model_filename = \"rf_model.pkl\"\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open(logistic_regression_model_filename, 'wb') as f:\n",
    "    pickle.dump(logistic_regression, f)\n",
    "\n",
    "with open(random_forest_model_filename, 'wb') as f:\n",
    "    pickle.dump(random_forest, f)\n",
    "    \n",
    "#uploads file to s3\n",
    "s3.upload_file(Filename=\"rf_model.pkl\", Bucket=BUCKET_NAME, Key=\"destination/model-output/rf_model.pkl\")\n",
    "s3.upload_file(Filename=\"logreg_model.pkl\", Bucket=BUCKET_NAME, Key=\"destination/model-output/logreg_model.pkl\")\n",
    "\n",
    "#removes the .pkl file after storing to s3\n",
    "try:\n",
    "    os.remove(logistic_regression_model_filename)\n",
    "    os.remove(random_forest_model_filename)\n",
    "except OSError:\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
